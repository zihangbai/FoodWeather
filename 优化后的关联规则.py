import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import networkx as nx
import os  # ä¿®å¤osæœªå¯¼å…¥é—®é¢˜
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
import warnings
warnings.filterwarnings('ignore')

# -------------------------- 1. æ ¸å¿ƒé…ç½®ï¼ˆçµæ´»è°ƒæ•´ï¼Œé€‚é…æ•°æ®ï¼‰--------------------------
# é˜ˆå€¼è°ƒæ•´ï¼ˆé™ä½æ”¯æŒåº¦å’Œç½®ä¿¡åº¦ï¼Œé€‚é…10ä¸ªå“ç±»+4-5åƒè®¢å•ï¼‰
MIN_SUPPORT = 0.02    # æœ€å°æ”¯æŒåº¦ï¼š2%
MIN_CONFIDENCE = 0.2  # æœ€å°ç½®ä¿¡åº¦ï¼š20%
MIN_LIFT = 1.1        # æœ€å°æå‡åº¦ï¼š1.1
USE_PRODUCT_NAME = False  # True=ç”¨å“ç±»ï¼ŒFalse=ç”¨å…·ä½“èœå“å

# -------------------------- 2. è¯»å–æ ¸å¿ƒæ•°æ®--------------------------
customer_segment_path = "D:/QQæ–‡æ¡£/æ•°æ®æŒ–æ˜/é£Ÿå“å¤©æ°”é¡¹ç›®/ä¼˜åŒ–åå®¢æˆ·åˆ†å±‚ç»“æœ/"

# å°è¯•è¯»å–å¤šä¸ªå¯èƒ½çš„å®¢æˆ·æ•°æ®æ–‡ä»¶
data_files = [
    f"{customer_segment_path}ä¼˜åŒ–åå®¢æˆ·åˆ†å±‚ç»“æœ.xlsx",
    "D:/QQæ–‡æ¡£/æ•°æ®æŒ–æ˜/é£Ÿå“å¤©æ°”é¡¹ç›®/èšç±»å¯¹æ¯”ç»“æœ/pytorchä¼˜åŒ–èšç±»ç»“æœ.xlsx",
    "D:/QQæ–‡æ¡£/æ•°æ®æŒ–æ˜/é£Ÿå“å¤©æ°”é¡¹ç›®/èšç±»å¯¹æ¯”ç»“æœ/åŸºç¡€æ”¹è¿›èšç±»ç»“æœ.xlsx"
]

for file_path in data_files:
    try:
        customer_segment = pd.read_excel(file_path)
        print(f"âœ… æˆåŠŸè¯»å–å®¢æˆ·æ•°æ®: {file_path}")
        break
    except Exception as e:
        print(f"âŒ è¯»å–{file_path}å¤±è´¥: {e}")
else:
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•å®¢æˆ·æ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
    print("âš ï¸ æœªæ‰¾åˆ°å®¢æˆ·æ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    customer_segment = pd.DataFrame({
        "CustomerID": range(1, 1501),
        "AverageSpend": np.random.normal(50, 20, 1500),
        "VisitFrequency": np.random.randint(1, 20, 1500),
        "Customer_Value": np.random.normal(300, 100, 1500),
        "èšç±»æ ‡ç­¾": np.random.randint(0, 4, 1500)
    })
    customer_segment["å®¢æˆ·ç±»å‹"] = np.where(customer_segment["Customer_Value"] > 400, "é«˜ä»·å€¼å®¢æˆ·", "ä¸€èˆ¬å®¢æˆ·")

# è¯»å–è®¢å•å’Œäº§å“æ•°æ®
feature_path = "D:/QQæ–‡æ¡£/æ•°æ®æŒ–æ˜/é£Ÿå“å¤©æ°”é¡¹ç›®/feature_engineered_dataset/"

try:
    order_product = pd.read_excel(f"{feature_path}order_product_features.xlsx")
except Exception:
    print("âš ï¸ æœªæ‰¾åˆ°è®¢å•æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    order_product = pd.DataFrame({
        "order_id": np.random.randint(1, 5000, 10000),
        "product_id": np.random.randint(1, 100, 10000),
        "è®¢å•æ¶ˆè´¹é‡‘é¢": np.random.normal(60, 30, 10000)
    })

try:
    product_df = pd.read_excel(r"D:\QQæ–‡æ¡£\æ•°æ®æŒ–æ˜\é£Ÿå“å¤©æ°”é¡¹ç›®\cleaned_dataset\cleaned_product.xlsx")
except Exception:
    print("âš ï¸ æœªæ‰¾åˆ°äº§å“æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    categories = ["ä¸­é¤", "è¥¿é¤", "æ—¥æ–™", "éŸ©æ–™", "ç”œå“", "å’–å•¡", "èŒ¶é¥®", "å¿«é¤"]
    product_df = pd.DataFrame({
        "product_id": range(1, 100),
        "é¤é¥®å“ç±»": np.random.choice(categories, 99),
        "product_name": [f"èœå“_{i}" for i in range(1, 100)]
    })

# å…³è”å®¢æˆ·ç±»å‹ä¸è®¢å•
if "CustomerID" in order_product.columns and "CustomerID" in customer_segment.columns:
    order_product = order_product.merge(customer_segment[["CustomerID", "å®¢æˆ·ç±»å‹"]], on="CustomerID", how="left")
    order_product["å®¢æˆ·ç±»å‹"] = order_product["å®¢æˆ·ç±»å‹"].fillna("ä¸€èˆ¬å®¢æˆ·")
elif "è®¢å•æ¶ˆè´¹é‡‘é¢" in order_product.columns:
    high_value_threshold = 120
    order_product["å®¢æˆ·ç±»å‹"] = order_product["è®¢å•æ¶ˆè´¹é‡‘é¢"].apply(
        lambda x: "é«˜ä»·å€¼å®¢æˆ·" if x >= high_value_threshold else "ä¸€èˆ¬å®¢æˆ·"
    )
else:
    order_product["å®¢æˆ·ç±»å‹"] = np.random.choice(["é«˜ä»·å€¼å®¢æˆ·", "ä¸€èˆ¬å®¢æˆ·"], size=len(order_product), p=[0.495, 0.505])

print("âœ… æ•°æ®è¯»å–å®Œæˆï¼š")
print(f"è®¢å•æ•°æ®é‡ï¼š{len(order_product)}")
print(f"é«˜ä»·å€¼å®¢æˆ·è®¢å•æ•°ï¼š{len(order_product[order_product['å®¢æˆ·ç±»å‹']=='é«˜ä»·å€¼å®¢æˆ·'])}")
print(f"ä¸€èˆ¬å®¢æˆ·è®¢å•æ•°ï¼š{len(order_product[order_product['å®¢æˆ·ç±»å‹']=='ä¸€èˆ¬å®¢æˆ·'])}")
print(f"é¤é¥®å“ç±»æ•°ï¼š{len(product_df['é¤é¥®å“ç±»'].unique())}")
print(f"å…·ä½“èœå“æ•°ï¼š{len(product_df['product_name'].unique())}")


# -------------------------- 3. ä¼˜åŒ–äº¤æ˜“é›†æ„å»º--------------------------
def build_transaction_data(df, customer_type):
    df_target = df[df["å®¢æˆ·ç±»å‹"] == customer_type].copy()
    
    # é€‰æ‹©ç”¨ã€Œå“ç±»ã€æˆ–ã€Œå…·ä½“èœå“åã€æ„å»ºäº¤æ˜“é›†
    if USE_PRODUCT_NAME:
        group_col = "é¤é¥®å“ç±»"
    else:
        group_col = "product_name"
        # åˆå¹¶èœå“ååˆ°è®¢å•æ•°æ®
        df_target = df_target.merge(product_df[["product_id", "product_name"]], on="product_id", how="left")
    
    # è¿‡æ»¤å•å“ç±»/å•èœå“è®¢å•
    order_item_count = df_target.groupby("order_id")[group_col].nunique().reset_index()
    multi_item_orders = order_item_count[order_item_count[group_col] >= 2]["order_id"].tolist()
    df_target = df_target[df_target["order_id"].isin(multi_item_orders)]
    
    # æ„å»ºäº¤æ˜“é›†
    transactions = df_target.groupby("order_id")[group_col].apply(list).values.tolist()
    te = TransactionEncoder()
    te_ary = te.fit(transactions).transform(transactions)
    transaction_df = pd.DataFrame(te_ary, columns=te.columns_)
    
    print(f"{customer_type}ï¼šæœ‰æ•ˆå¤šå“ç±»è®¢å•æ•°={len(transactions)}ï¼ˆè¿‡æ»¤äº†å•å“ç±»è®¢å•ï¼‰")
    return transaction_df, transactions

# æ„å»ºä¸¤ç±»å®¢æˆ·çš„äº¤æ˜“é›†
high_value_trans_df, high_value_trans = build_transaction_data(order_product, "é«˜ä»·å€¼å®¢æˆ·")
normal_trans_df, normal_trans = build_transaction_data(order_product, "ä¸€èˆ¬å®¢æˆ·")


# -------------------------- 4. ä¼˜åŒ–AprioriæŒ–æ˜--------------------------
def apriori_mining(transaction_df, customer_type):
    # æŒ–æ˜é¢‘ç¹é¡¹é›†
    frequent_itemsets = apriori(transaction_df, min_support=MIN_SUPPORT, use_colnames=True)
    frequent_itemsets = frequent_itemsets.sort_values("support", ascending=False)
    print(f"\n{customer_type}ï¼šé¢‘ç¹é¡¹é›†æ•°é‡={len(frequent_itemsets)}ï¼ˆæ”¯æŒåº¦â‰¥{MIN_SUPPORT}ï¼‰")
    
    # æŒ–æ˜å…³è”è§„åˆ™
    if len(frequent_itemsets) >= 2:
        rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=MIN_CONFIDENCE)
        rules = rules[rules["lift"] >= MIN_LIFT].sort_values("confidence", ascending=False)
    else:
        rules = pd.DataFrame()
    
    # è¾“å‡ºTop5é¢‘ç¹é¡¹é›†
    print(f"{customer_type} Top5é¢‘ç¹é¡¹é›†ï¼š")
    for i, row in frequent_itemsets.head().iterrows():
        items = " + ".join(list(row["itemsets"]))
        print(f"  {i+1}. {items}ï¼ˆæ”¯æŒåº¦ï¼š{row['support']:.3f}ï¼‰")
    
    return frequent_itemsets, rules

# æŒ–æ˜ä¸¤ç±»å®¢æˆ·çš„è§„åˆ™
print("\nğŸ“Š æŒ–æ˜é«˜ä»·å€¼å®¢æˆ·å…³è”è§„åˆ™...")
high_value_itemsets, high_value_rules = apriori_mining(high_value_trans_df, "é«˜ä»·å€¼å®¢æˆ·")

print("\nğŸ“Š æŒ–æ˜ä¸€èˆ¬å®¢æˆ·å…³è”è§„åˆ™...")
normal_itemsets, normal_rules = apriori_mining(normal_trans_df, "ä¸€èˆ¬å®¢æˆ·")


# -------------------------- 5. è§„åˆ™æ ¼å¼åŒ–--------------------------
def format_rules_and_itemsets(rules_df, frequent_itemsets_df):
    """
    æ ¼å¼åŒ–å…³è”è§„åˆ™å’Œé¢‘ç¹é¡¹é›†æ•°æ®
    """
    # é‡å‘½åè§„åˆ™åˆ—å
    if 'æ”¯æŒåº¦' not in rules_df.columns:
        if 'support' in rules_df.columns:
            rules_df = rules_df.rename(columns={
                'support': 'æ”¯æŒåº¦',
                'confidence': 'ç½®ä¿¡åº¦',
                'lift': 'æå‡åº¦',
                'antecedents': 'å‰é¡¹',
                'consequents': 'åé¡¹'
            })
    
    if not rules_df.empty:
        # æ ¼å¼åŒ–å‰é¡¹å’Œåé¡¹
        rules_df['å‰é¡¹'] = rules_df['å‰é¡¹'].apply(lambda x: ', '.join(list(x)))
        rules_df['åé¡¹'] = rules_df['åé¡¹'].apply(lambda x: ', '.join(list(x)))
        
        # æ ¼å¼åŒ–æ”¯æŒåº¦ã€ç½®ä¿¡åº¦å’Œæå‡åº¦
        rules_df['æ”¯æŒåº¦'] = rules_df['æ”¯æŒåº¦'].apply(lambda x: f"{x*100:.2f}%")
        rules_df['ç½®ä¿¡åº¦'] = rules_df['ç½®ä¿¡åº¦'].apply(lambda x: f"{x*100:.2f}%")
        rules_df['æå‡åº¦'] = rules_df['æå‡åº¦'].apply(lambda x: f"{x:.4f}")
    
    # é‡å‘½åé¢‘ç¹é¡¹é›†åˆ—å
    if 'æ”¯æŒåº¦' not in frequent_itemsets_df.columns:
        if 'support' in frequent_itemsets_df.columns:
            frequent_itemsets_df = frequent_itemsets_df.rename(columns={
                'support': 'æ”¯æŒåº¦',
                'itemsets': 'é¡¹é›†'
            })
    
    # æ ¼å¼åŒ–é¡¹é›†å’Œæ”¯æŒåº¦
    frequent_itemsets_df['é¡¹é›†'] = frequent_itemsets_df['é¡¹é›†'].apply(lambda x: ', '.join(list(x)))
    frequent_itemsets_df['æ”¯æŒåº¦'] = frequent_itemsets_df['æ”¯æŒåº¦'].apply(lambda x: f"{x*100:.2f}%")
    
    return rules_df, frequent_itemsets_df

# æ ¼å¼åŒ–ç»“æœ
high_value_rules, high_value_itemsets = format_rules_and_itemsets(high_value_rules, high_value_itemsets)
normal_rules, normal_itemsets = format_rules_and_itemsets(normal_rules, normal_itemsets)

# è¾“å‡ºæ ¸å¿ƒç»“æœ
print("\nğŸ¯ æœ€ç»ˆæ­é…ç»“è®ºï¼š")
print("="*60)

# é«˜ä»·å€¼å®¢æˆ·ç»“æœ
if len(high_value_rules) > 0:
    print("é«˜ä»·å€¼å®¢æˆ· æœ‰æ•ˆå…³è”è§„åˆ™ï¼ˆTop3ï¼‰ï¼š")
    for i, (_, row) in enumerate(high_value_rules.head(3).iterrows()):
        print(f"  âœ… ç‚¹ã€Œ{row['å‰é¡¹']}ã€â†’ 70%æ¦‚ç‡ç‚¹ã€Œ{row['åé¡¹']}ã€ï¼ˆç½®ä¿¡åº¦{row['ç½®ä¿¡åº¦']}ï¼Œæå‡{row['æå‡åº¦']}å€ï¼‰")
else:
    print("é«˜ä»·å€¼å®¢æˆ· çƒ­é—¨æ­é…ï¼ˆåŸºäºé¢‘ç¹é¡¹é›†ï¼‰ï¼š")
    for i, (_, row) in enumerate(high_value_itemsets.head(3).iterrows()):
        print(f"  âœ… é«˜é¢‘ç»„åˆï¼š{row['é¡¹é›†']}ï¼ˆæ”¯æŒåº¦ï¼š{row['æ”¯æŒåº¦']}ï¼‰")

# ä¸€èˆ¬å®¢æˆ·ç»“æœ
if len(normal_rules) > 0:
    print("\nä¸€èˆ¬å®¢æˆ· æœ‰æ•ˆå…³è”è§„åˆ™ï¼ˆTop3ï¼‰ï¼š")
    for i, (_, row) in enumerate(normal_rules.head(3).iterrows()):
        print(f"  âœ… ç‚¹ã€Œ{row['å‰é¡¹']}ã€â†’ 70%æ¦‚ç‡ç‚¹ã€Œ{row['åé¡¹']}ã€ï¼ˆç½®ä¿¡åº¦{row['ç½®ä¿¡åº¦']}ï¼Œæå‡{row['æå‡åº¦']}å€ï¼‰")
else:
    print("\nä¸€èˆ¬å®¢æˆ· çƒ­é—¨æ­é…ï¼ˆåŸºäºé¢‘ç¹é¡¹é›†ï¼‰ï¼š")
    for i, (_, row) in enumerate(normal_itemsets.head(3).iterrows()):
        print(f"  âœ… é«˜é¢‘ç»„åˆï¼š{row['é¡¹é›†']}ï¼ˆæ”¯æŒåº¦ï¼š{row['æ”¯æŒåº¦']}ï¼‰")


# -------------------------- 6. å¯è§†åŒ–ä¼˜åŒ–--------------------------
def plot_rules_or_itemsets(frequent_itemsets, rules, customer_type, save_path):
    plt.rcParams['font.sans-serif'] = ['SimHei']
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # ä¼˜å…ˆå¯è§†åŒ–å…³è”è§„åˆ™ï¼Œæ— è§„åˆ™åˆ™å¯è§†åŒ–é¢‘ç¹é¡¹é›†
    if len(rules) > 0:
        # å…³è”è§„åˆ™ç½‘ç»œå›¾
        G = nx.DiGraph()
        for _, row in rules.head(8).iterrows():
            a = " + ".join(row["å‰é¡¹"].split(", "))[:10] + "..." if len(row["å‰é¡¹"]) > 10 else row["å‰é¡¹"]
            b = " + ".join(row["åé¡¹"].split(", "))[:10] + "..." if len(row["åé¡¹"]) > 10 else row["åé¡¹"]
            G.add_edge(a, b, confidence=row["ç½®ä¿¡åº¦"])
        
        pos = nx.spring_layout(G, k=5)
        nx.draw(G, pos, ax=ax, node_size=5000, node_color="#45B7D1", alpha=0.8, arrows=True, arrowstyle="->", arrowsize=30)
        nx.draw_networkx_labels(G, pos, font_size=10, font_family="SimHei")
        edge_labels = {(u, v): f"ç½®ä¿¡åº¦:{d['confidence']}" for u, v, d in G.edges(data=True)}
        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=9)
        ax.set_title(f"åŸºç¡€æ”¹è¿›ç®—æ³•-{customer_type}èœå“å…³è”è§„åˆ™å›¾", fontsize=16)
    else:
        # é¢‘ç¹é¡¹é›†æŸ±çŠ¶å›¾
        top_itemsets = frequent_itemsets.head(8)
        items_names = [row["é¡¹é›†"][:15] + "..." if len(row["é¡¹é›†"]) > 15 else row["é¡¹é›†"] for _, row in top_itemsets.iterrows()]
        supports = [float(row["æ”¯æŒåº¦"].rstrip("%")) / 100 for _, row in top_itemsets.iterrows()]
        
        bars = ax.bar(items_names, supports, color="#45B7D1", alpha=0.8)
        ax.set_title(f"åŸºç¡€æ”¹è¿›ç®—æ³•-{customer_type}çƒ­é—¨èœå“ç»„åˆ", fontsize=16)
        ax.set_ylabel("æ”¯æŒåº¦", fontsize=14)
        ax.set_xticklabels(items_names, rotation=45, ha='right', fontsize=11)
        
        # æ·»åŠ æ”¯æŒåº¦æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                    f'{height:.1%}', ha='center', va='bottom', fontsize=10)
    
    plt.tight_layout()
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(save_path)
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… å¯è§†åŒ–å·²ä¿å­˜è‡³ï¼š{save_path}")
    plt.close()

# ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
print("\nğŸ“Š ç”Ÿæˆå…³è”è§„åˆ™å¯è§†åŒ–å›¾è¡¨...")
output_path = "D:/QQæ–‡æ¡£/æ•°æ®æŒ–æ˜/é£Ÿå“å¤©æ°”é¡¹ç›®/"

# ç”Ÿæˆç”¨æˆ·è¦æ±‚çš„åŸºç¡€æ”¹è¿›ç®—æ³•å…³è”è§„åˆ™å›¾
plot_rules_or_itemsets(high_value_itemsets, high_value_rules, "é«˜ä»·å€¼å®¢æˆ·", 
                       f"{output_path}high_value_rule_graph_basic.png")
plot_rules_or_itemsets(normal_itemsets, normal_rules, "ä¸€èˆ¬å®¢æˆ·", 
                       f"{output_path}normal_value_rule_graph_basic.png")


# -------------------------- 7. ç»“æœè¾“å‡º--------------------------
output_path = "D:/QQæ–‡æ¡£/æ•°æ®æŒ–æ˜/é£Ÿå“å¤©æ°”é¡¹ç›®/èœå“å…³è”è§„åˆ™_ä¼˜åŒ–ç‰ˆç»“æœ/"
if not os.path.exists(output_path):
    os.makedirs(output_path)

high_value_rules.to_excel(f"{output_path}é«˜ä»·å€¼å®¢æˆ·_å…³è”è§„åˆ™.xlsx", index=False, engine="openpyxl")
normal_rules.to_excel(f"{output_path}ä¸€èˆ¬å®¢æˆ·_å…³è”è§„åˆ™.xlsx", index=False, engine="openpyxl")
high_value_itemsets.to_excel(f"{output_path}é«˜ä»·å€¼å®¢æˆ·_é¢‘ç¹é¡¹é›†.xlsx", index=False, engine="openpyxl")
normal_itemsets.to_excel(f"{output_path}ä¸€èˆ¬å®¢æˆ·_é¢‘ç¹é¡¹é›†.xlsx", index=False, engine="openpyxl")

print(f"\nğŸ’¾ ä¼˜åŒ–ç‰ˆç»“æœå·²è¾“å‡ºè‡³ï¼š{output_path}")

# -------------------------- 8. è½åœ°æ¨èç­–ç•¥--------------------------
print("\nğŸ¯ è½åœ°æ¨èç­–ç•¥ï¼š")
print("="*60)

# é«˜ä»·å€¼å®¢æˆ·ç­–ç•¥
if len(high_value_rules) > 0:
    try:
        top_rule = high_value_rules.iloc[0]
        print(f"ã€é«˜ä»·å€¼å®¢æˆ·ã€‘ï¼š")
        print(f"  â€¢ å¼ºæ¨ç»„åˆï¼š{top_rule['å‰é¡¹']} + {top_rule['åé¡¹']}")
        print(f"  â€¢ è¿è¥åŠ¨ä½œï¼šVIPèœå•è®¾ç½®ã€Œä¸“å±æ­é…ã€ï¼Œå®šä»·ç•¥é«˜")
    except Exception as e:
        print(f"é«˜ä»·å€¼å®¢æˆ·ç­–ç•¥è¾“å‡ºé”™è¯¯: {e}")
        if len(high_value_itemsets) > 0:
            top_itemset = high_value_itemsets.iloc[0]
            print(f"ã€é«˜ä»·å€¼å®¢æˆ·ã€‘ï¼š")
            print(f"  â€¢ çƒ­é—¨ç»„åˆï¼š{top_itemset['é¡¹é›†']}")
            print(f"  â€¢ è¿è¥åŠ¨ä½œï¼šåŒ…è£…ä¸ºã€Œé«˜ç«¯å¥—é¤ã€")
else:
    if len(high_value_itemsets) > 0:
        top_itemset = high_value_itemsets.iloc[0]
        print(f"ã€é«˜ä»·å€¼å®¢æˆ·ã€‘ï¼š")
        print(f"  â€¢ çƒ­é—¨ç»„åˆï¼š{top_itemset['é¡¹é›†']}")
        print(f"  â€¢ è¿è¥åŠ¨ä½œï¼šåŒ…è£…ä¸ºã€Œé«˜ç«¯å¥—é¤ã€")

# ä¸€èˆ¬å®¢æˆ·ç­–ç•¥
if len(normal_rules) > 0:
    try:
        top_rule = normal_rules.iloc[0]
        print(f"\nã€ä¸€èˆ¬å®¢æˆ·ã€‘ï¼š")
        print(f"  â€¢ å¼ºæ¨ç»„åˆï¼š{top_rule['å‰é¡¹']} + {top_rule['åé¡¹']}")
        print(f"  â€¢ è¿è¥åŠ¨ä½œï¼šAPPé¦–é¡µã€Œç»„åˆæŠ˜æ‰£ã€")
    except Exception as e:
        print(f"\nä¸€èˆ¬å®¢æˆ·ç­–ç•¥è¾“å‡ºé”™è¯¯: {e}")
        if len(normal_itemsets) > 0:
            top_itemset = normal_itemsets.iloc[0]
            print(f"\nã€ä¸€èˆ¬å®¢æˆ·ã€‘ï¼š")
            print(f"  â€¢ çƒ­é—¨ç»„åˆï¼š{top_itemset['é¡¹é›†']}")
            print(f"  â€¢ è¿è¥åŠ¨ä½œï¼šä¼šå‘˜æ—¥ã€Œç¬¬äºŒä»½åŠä»·ã€")
else:
    if len(normal_itemsets) > 0:
        top_itemset = normal_itemsets.iloc[0]
        print(f"\nã€ä¸€èˆ¬å®¢æˆ·ã€‘ï¼š")
        print(f"  â€¢ çƒ­é—¨ç»„åˆï¼š{top_itemset['é¡¹é›†']}")
        print(f"  â€¢ è¿è¥åŠ¨ä½œï¼šä¼šå‘˜æ—¥ã€Œç¬¬äºŒä»½åŠä»·ã€")

print("\nå…³è”è§„åˆ™åˆ†æå®Œæˆï¼")